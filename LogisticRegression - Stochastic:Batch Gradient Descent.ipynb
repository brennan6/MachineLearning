{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats, io\n",
    "from scipy.special import expit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionModel(object):\n",
    "    \n",
    "    def __init__(self, name, seed = 42):\n",
    "        if name != 'data':\n",
    "            raise ValueError('Incorrect Dataset')\n",
    "        np.random.seed(seed)\n",
    "        self.name = name\n",
    "        self.data = None\n",
    "        self.trainOrig = None\n",
    "        self.trLabelsOrig = None\n",
    "        self.train = None\n",
    "        self.trLabels = None\n",
    "        self.val = None\n",
    "        self.valLabels = None\n",
    "        self.test = None\n",
    "        self.dim = None\n",
    "        self.weight = None\n",
    "        self.pred = None\n",
    "        \n",
    "        self.load_data()\n",
    "        self.split(1000)\n",
    "        \n",
    "    def load_data(self):\n",
    "        self.data = io.loadmat(self.name + '.mat')\n",
    "        print('Loaded: ' + self.name)\n",
    "        self.normalize()\n",
    "        self.trainOrig = self.data['X']\n",
    "        self.trLabelsOrig = self.data['y'].reshape(-1)\n",
    "        self.test  = self.data['X_test']\n",
    "        self.test = np.apply_along_axis(self.add1, 1, self.test)\n",
    "        \n",
    "        print('Training size (Before Split): ' + str(len(self.trainOrig)))\n",
    "        print('Training labels (Before Split):' + str(len(self.trLabelsOrig)))\n",
    "        print('Test size: ' + str(len(self.test)))\n",
    "        \n",
    "        \n",
    "    def split(self,valSize):\n",
    "        totalLen = len(self.trainOrig)\n",
    "        trainSize = totalLen - valSize\n",
    "        randIdx = np.random.permutation(totalLen)\n",
    "        self.train = self.trainOrig[randIdx][:trainSize]\n",
    "        self.train = np.apply_along_axis(self.add1, 1, self.train)\n",
    "        self.trLabels = self.trLabelsOrig[randIdx][:trainSize]\n",
    "        self.val = self.trainOrig[randIdx][trainSize:]\n",
    "        self.val = np.apply_along_axis(self.add1, 1, self.val)\n",
    "        self.valLabels = self.trLabelsOrig[randIdx][trainSize:]\n",
    "        self.dim = self.train.shape\n",
    "        \n",
    "        print('Training Data Len: ' + str(len(self.train)))\n",
    "        print('Training Labels Len: ' + str(len(self.trLabels)))\n",
    "        print('Validation Data Len: ' + str(len(self.val)))\n",
    "        print('Validation Labels Len: ' + str(len(self.valLabels)))\n",
    "\n",
    "    def normalize(self):\n",
    "        for idx in ['X', 'X_test']:\n",
    "            mean = np.mean(self.data[idx], axis = 0)\n",
    "            std = np.std(self.data[idx], axis = 0)\n",
    "            z_score = lambda val: (val-mean)/std\n",
    "            self.data[idx] = np.apply_along_axis(z_score,1,self.data[idx])\n",
    "\n",
    "    def add1(self, arr):\n",
    "        return np.append(arr, [[1]])\n",
    "    \n",
    "    def cost(self,X,y,w,l):\n",
    "        s = expit(X @ w)\n",
    "        s = np.maximum(s, 1e-7)\n",
    "        s = np.minimum(s, 1-1e-7)\n",
    "        return l*w@w - (1/len(X))*(y.dot(np.log(s)) + (1-y).dot(np.log(1-s)))\n",
    "    \n",
    "    def grad_penalty(self,X,y,w,l):\n",
    "        s = expit(X @ w)\n",
    "        return -X.T.dot(y - s) + 2*l*w\n",
    "        \n",
    "    def gradient_descent(self,typeGrad,e,l,changingE,tol=1e-7,graph=True,numIter=1000,maxLoops = 5):\n",
    "        costLst, valCost = [], []\n",
    "        converged = False\n",
    "        w = np.zeros(self.dim[1])\n",
    "        J_o, J_new = float(\"Inf\"), self.cost(self.train, self.trLabels, w, l)\n",
    "        i = 0\n",
    "        if typeGrad == 'batch':\n",
    "            while i < numIter and not converged:\n",
    "                w = w - e * self.grad_penalty(self.train, self.trLabels, w, l)\n",
    "                J_o, J_new = J_new, self.cost(self.train, self.trLabels, w, l)      \n",
    "                costLst.append(J_o)\n",
    "                valCost.append(self.cost(self.val, self.valLabels, w, l))\n",
    "                i+=1\n",
    "                if abs(J_o - J_new) < tol:\n",
    "                    converged = True\n",
    "                    break\n",
    "        if typeGrad == 'stochastic':\n",
    "            numLoops = 0\n",
    "            while numLoops < maxLoops and not converged:\n",
    "                numLoops += 1\n",
    "                randIdx = np.random.permutation(self.dim[0])\n",
    "                X = self.train[randIdx]\n",
    "                y = self.trLabels[randIdx]\n",
    "                for x_i, y_i in zip(X, y):\n",
    "                    if changingE:\n",
    "                        w = w - e/(.03*(i+10)) * self.grad_penalty(x_i, y_i, w, l)\n",
    "                    else:\n",
    "                        w = w - e*self.grad_penalty(x_i, y_i, w, l)\n",
    "                    J_o, J_new = J_new, self.cost(X, y, w, l)\n",
    "                    costLst.append(J_o)\n",
    "                    valCost.append(self.cost(self.val, self.valLabels, w, l))\n",
    "                    i+=1\n",
    "                    if abs(J_o - J_new) < tol:\n",
    "                        converged = True\n",
    "                        break\n",
    "        print(\"Cost Final: \" + str(J_o))\n",
    "        print(\"Converged:\" + str(i) + \"iterations\")\n",
    "        if graph:\n",
    "            plt.plot(costLst, label = \"Training\")\n",
    "            plt.plot(valCost, label = \"Validation\")\n",
    "            plt.xlabel(\"Number of Iterations\")\n",
    "            plt.ylabel(\"Cost\")\n",
    "            plt.title(\"Cost Over Iterations\")\n",
    "        self.weight = w\n",
    "    \n",
    "\n",
    "    def experiment(self,typeGrad,testData,e,l,changingE):\n",
    "        self.gradient_descent(typeGrad,e,l,changingE,graph=False)\n",
    "        y_val = expit(testData @ self.weight)\n",
    "        y_pred = (y_val > 0.5).astype(np.int)\n",
    "        self.pred = y_pred\n",
    "        return y_pred\n",
    "    \n",
    "    def accuracy(self,labels):\n",
    "        return np.sum(self.pred.reshape(-1) == labels.reshape(-1))/len(self.pred)                \n",
    "                \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.03451128789693964\n",
      "Converged:208iterations\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = LogisticRegressionModel('data', 42)\n",
    "m.gradient_descent('batch', .01, 1e-6, changingE = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.5129414392036031\n",
      "Converged:1000iterations\n",
      "LR: 1e-07  RegParam: 0.01  Accuracy: 0.962\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.5121343753396624\n",
      "Converged:1000iterations\n",
      "LR: 1e-07  RegParam: 0.001  Accuracy: 0.962\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.5120536688016132\n",
      "Converged:1000iterations\n",
      "LR: 1e-07  RegParam: 0.0001  Accuracy: 0.962\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.5120455981462916\n",
      "Converged:1000iterations\n",
      "LR: 1e-07  RegParam: 1e-05  Accuracy: 0.962\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.5120447910807444\n",
      "Converged:1000iterations\n",
      "LR: 1e-07  RegParam: 1e-06  Accuracy: 0.962\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.5120447103741896\n",
      "Converged:1000iterations\n",
      "LR: 1e-07  RegParam: 1e-07  Accuracy: 0.962\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.2038027086929647\n",
      "Converged:1000iterations\n",
      "LR: 1e-06  RegParam: 0.01  Accuracy: 0.977\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.18553734429978758\n",
      "Converged:1000iterations\n",
      "LR: 1e-06  RegParam: 0.001  Accuracy: 0.977\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.18371077663228988\n",
      "Converged:1000iterations\n",
      "LR: 1e-06  RegParam: 0.0001  Accuracy: 0.977\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.18352811955325443\n",
      "Converged:1000iterations\n",
      "LR: 1e-06  RegParam: 1e-05  Accuracy: 0.977\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.1835098538422282\n",
      "Converged:1000iterations\n",
      "LR: 1e-06  RegParam: 1e-06  Accuracy: 0.977\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.1835080272710942\n",
      "Converged:1000iterations\n",
      "LR: 1e-06  RegParam: 1e-07  Accuracy: 0.977\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.17324801893735775\n",
      "Converged:1000iterations\n",
      "LR: 1e-05  RegParam: 0.01  Accuracy: 0.991\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.07048163099075341\n",
      "Converged:1000iterations\n",
      "LR: 1e-05  RegParam: 0.001  Accuracy: 0.991\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.06020321401375592\n",
      "Converged:1000iterations\n",
      "LR: 1e-05  RegParam: 0.0001  Accuracy: 0.991\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.059175354531653845\n",
      "Converged:1000iterations\n",
      "LR: 1e-05  RegParam: 1e-05  Accuracy: 0.991\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.05907256840559691\n",
      "Converged:1000iterations\n",
      "LR: 1e-05  RegParam: 1e-06  Accuracy: 0.991\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.05906228979121318\n",
      "Converged:1000iterations\n",
      "LR: 1e-05  RegParam: 1e-07  Accuracy: 0.991\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.357604435955906\n",
      "Converged:1000iterations\n",
      "LR: 0.0001  RegParam: 0.01  Accuracy: 0.995\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.06444357566896411\n",
      "Converged:268iterations\n",
      "LR: 0.0001  RegParam: 0.001  Accuracy: 0.992\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.041655862093800636\n",
      "Converged:1000iterations\n",
      "LR: 0.0001  RegParam: 0.0001  Accuracy: 0.995\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.03877904273626833\n",
      "Converged:1000iterations\n",
      "LR: 0.0001  RegParam: 1e-05  Accuracy: 0.995\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.038491356274646026\n",
      "Converged:1000iterations\n",
      "LR: 0.0001  RegParam: 1e-06  Accuracy: 0.995\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.0384625875832243\n",
      "Converged:1000iterations\n",
      "LR: 0.0001  RegParam: 1e-07  Accuracy: 0.995\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.6568052834526016\n",
      "Converged:1000iterations\n",
      "LR: 0.001  RegParam: 0.01  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.0973664924757946\n",
      "Converged:1000iterations\n",
      "LR: 0.001  RegParam: 0.001  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.04034624649051768\n",
      "Converged:448iterations\n",
      "LR: 0.001  RegParam: 0.0001  Accuracy: 0.995\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost Final: 0.035192866625506684\n",
      "Converged:1000iterations\n",
      "LR: 0.001  RegParam: 1e-05  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.03462706691031586\n",
      "Converged:1000iterations\n",
      "LR: 0.001  RegParam: 1e-06  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.03457048635840218\n",
      "Converged:1000iterations\n",
      "LR: 0.001  RegParam: 1e-07  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.8000429683031589\n",
      "Converged:963iterations\n",
      "LR: 0.01  RegParam: 0.01  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.11250010130894003\n",
      "Converged:809iterations\n",
      "LR: 0.01  RegParam: 0.001  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.04219741338341202\n",
      "Converged:625iterations\n",
      "LR: 0.01  RegParam: 0.0001  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.03534560097392368\n",
      "Converged:172iterations\n",
      "LR: 0.01  RegParam: 1e-05  Accuracy: 0.996\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.03451128789693964\n",
      "Converged:208iterations\n",
      "LR: 0.01  RegParam: 1e-06  Accuracy: 0.997\n",
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.03442628911709663\n",
      "Converged:202iterations\n",
      "LR: 0.01  RegParam: 1e-07  Accuracy: 0.997\n"
     ]
    }
   ],
   "source": [
    "lrs = [10**(-7), 10**(-6), 10**(-5), 10**(-4), 10**(-3), 10**(-2)]\n",
    "regs = [.01,.001,.0001,.00001,.000001,.0000001]\n",
    "for lr in lrs:\n",
    "    for reg in regs:\n",
    "        mod = LogisticRegressionModel('data', 42)\n",
    "        mod.experiment('batch', mod.val, lr, reg, changingE = False)\n",
    "        print(\"LR: \"+str(lr)+'  RegParam: '+str(reg)+ '  Accuracy: '+ str(mod.accuracy(mod.valLabels)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: data\n",
      "Training size (Before Split): 6000\n",
      "Training labels (Before Split):6000\n",
      "Test size: 497\n",
      "Training Data Len: 5000\n",
      "Training Labels Len: 5000\n",
      "Validation Data Len: 1000\n",
      "Validation Labels Len: 1000\n",
      "Cost Final: 0.03451128789693964\n",
      "Converged:208iterations\n"
     ]
    }
   ],
   "source": [
    "#Cell for submission\n",
    "m = LogisticRegressionModel('data', 42)\n",
    "y_pred = m.experiment('batch', m.test, .01, 1e-6, changingE = False).reshape(-1)\n",
    "\n",
    "def results_to_csv(y_test):\n",
    "    y_test = y_test.astype(int)\n",
    "    df = pd.DataFrame({'Category': y_test})\n",
    "    df.index += 1  # Ensures that the index starts at 1. \n",
    "    df.to_csv('submission.csv', index_label='Id')\n",
    "\n",
    "results_to_csv(y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
